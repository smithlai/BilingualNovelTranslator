{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97a66734-48c6-44f3-bd18-b3370f924820",
   "metadata": {},
   "source": [
    "# V7\n",
    "The V6 fixed some json issues with llm, but not all.  \n",
    "There are still some errors about missing `,` or `\\`  \n",
    "  \n",
    "LLM is not stable in fixing these kind of issues.  \n",
    "So a classic library might be a better choice:  \n",
    "https://github.com/mangiucugna/json_repair\n",
    "\n",
    "We will make `repair_markdown_json()` to replace previous `verify_json()` and `fix_json()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b222aec-6c75-4ba0-a691-1787effc587b",
   "metadata": {},
   "source": [
    "## Gemini Pro API and OpenAI API\n",
    "Check [Bilingual-NovelTranslator-v1.ipynb](Bilingual-NovelTranslator-v1.ipynb) for more information.\n",
    "\n",
    "**Note** : Remember to fill you api key in `.env` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c52cbbd-3d5f-4869-bd14-5a8f1c6d0219",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import utils\n",
    "\n",
    "geminipro, openai = utils.init_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cc5aaf9-05bc-4e3f-a88d-0e07fe571fc6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import utils\n",
    "# Check [Bilingual-NovelTranslator-v6.ipynb](Bilingual-NovelTranslator-v6.ipynb) for more information.\n",
    "utils.monkeypatch_split_text_with_regex()\n",
    "\n",
    "# refer to V5 for more info\n",
    "split_paragraph = utils.split_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0401d22a-9b6b-4167-ad12-053d9970ca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU json_repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a61470-32c6-40ce-991b-3ce20c7d7e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_markdown_json(bad_markdown_json):\n",
    "    from json_repair import repair_json\n",
    "    import json, re\n",
    "    pattern = re.compile(r\"```json(.*?)```\", re.DOTALL)\n",
    "    matches = pattern.findall(bad_markdown_json)\n",
    "    merged_list = []\n",
    "    for match in matches:\n",
    "        try:\n",
    "            json_data = repair_json(match.strip(), return_objects=True)\n",
    "            new_json = json.dumps(json_data, indent=4, ensure_ascii=False)\n",
    "            # print(new_json)\n",
    "            merged_list.append(new_json)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(e)\n",
    "            print(f\"Error decoding JSON in block: {match}\")\n",
    "    return \"\\n\".join([\"```json\"] + merged_list +[\"```\\n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e143b7e7-720b-4870-90a8-aca5c5932b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoprocess_paragraph(llm, paragraphs, target_file, start=0):\n",
    "    from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "    from langchain_core.output_parsers.string import StrOutputParser\n",
    "    prompt = PromptTemplate.from_template(\n",
    "\"\"\"You are a professional translation assistant. Your task is to translate a paragraph from english to traditional Chinese.\n",
    "\n",
    "There will be an OCR document with many layout issues.\n",
    "You should first try to find out every complete sentence and speech in the article,\n",
    "and check and fix it if the sentence or speech got split(linebreak) by mistake.\n",
    "Every sentence or speech should be separated and distinct.\n",
    "Your shoud check and fix misspellings and typos a well.\n",
    "\n",
    "Then you should translate each sentence into zh-tw.\n",
    "If a sentence is nonsense, you can just copy it to the correction and translation fields without any modification.\n",
    "\n",
    "The output should be a markdown code snippet formatted in the following json schema, including the leading and trailing \"```json\" and \"```\":\n",
    "\n",
    "```json\n",
    "[\n",
    "    {{\n",
    "        \"correction\": string  // the sentence after error correction\n",
    "        \"zh-tw\": string  // the translated sentence zh-tw\n",
    "    }},\n",
    "    {{\n",
    "        \"correction\": string  // the sentence after error correction\n",
    "        \"zh-tw\": string  // the translated sentence zh-tw\n",
    "    }},\n",
    "    .......\n",
    "    ........\n",
    "    {{\n",
    "        \"correction\": string  // the sentence after error correction\n",
    "        \"zh-tw\": string  // the translated sentence zh-tw\n",
    "    }}\n",
    "]\n",
    "```\n",
    "\n",
    "Example:\n",
    "---\n",
    "input:\n",
    "\n",
    "Eefore one girl and another even younger one stood a figure in \n",
    "full p1ate armor brandishing a 5word.Lhe blade swung, sparkl-\n",
    "ing in the sun1ight as if to say that taking their lives in a \n",
    "single stroke would be an act of mercy.\n",
    "\"No, let me go\" She begged.\n",
    "\"\"\n",
    "---\n",
    "output:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {{\n",
    "        \"correction\": \"Before one girl and another even younger one stood a figure in full plate armor brandishing a sword.\",\n",
    "        \"zh-tw\": \"在一名少女以及比她更年輕的少女面前，站著一位身穿全身板甲、揮舞著劍的男子。\"\n",
    "    }},\n",
    "    {{\n",
    "        \"correction\": \"The blade swung, sparkling in the sunlight as if to say that taking their lives in a single stroke would be an act of mercy.\"\n",
    "        \"zh-tw\": \"刀鋒揮動，在陽光下閃爍，彷彿在說一刀奪命是仁慈的作為。\"\n",
    "    }},\n",
    "    {{\n",
    "        \"correction\": \"“No, let me go”\"\n",
    "        \"zh-tw\": \"不，放我走。\"\n",
    "    }},\n",
    "    {{\n",
    "        \"correction\": \"She begged.\"\n",
    "        \"zh-tw\": \"她如此哀求著。\"\n",
    "    }},\n",
    "]\n",
    "```\n",
    "---\n",
    "\n",
    "\n",
    "The original paragraph is as following:\n",
    "\n",
    "{input}\n",
    "\n",
    "\"\"\")\n",
    "    print(f\"using llm: {llm}\")\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    translated=[]\n",
    "    from tqdm.notebook import tqdm, trange\n",
    "    errorindx = -1\n",
    "    with tqdm(total=len(paragraphs)) as progress_bar:\n",
    "        for i, paragraph in enumerate(paragraphs):\n",
    "            if i < start:\n",
    "                progress_bar.update(1)\n",
    "                continue\n",
    "            if len(paragraph.strip()) > 0:\n",
    "                try:\n",
    "                    # temp = \"\"\n",
    "                    # for chunk in chain.stream({\"input\": paragraph}):\n",
    "                    #     print(chunk, end=\"\", flush=True)\n",
    "                    #     temp += chunk\n",
    "                    # print(\"\\n------\\n\")    \n",
    "                    temp = chain.invoke({\"input\": paragraph})\n",
    "                except Exception as e:\n",
    "                    print(f\"Error occurs at {i}:\")\n",
    "                    print(paragraph)\n",
    "                    print(e)\n",
    "                    errorindx = i\n",
    "                    return errorindx,translated;\n",
    "                    \n",
    "                temp = repair_markdown_json(temp)\n",
    "                # retry=0\n",
    "                # temp2 = temp\n",
    "                # while retry < 3:  # We retry to fix this 3 times, if we cannot fix it, just don'y touch it.\n",
    "                #     err_msg = verify_json(temp2)\n",
    "                #     if err_msg:\n",
    "                #         temp2 = fix_json(llm, temp2, err_msg)\n",
    "                #         retry += 1\n",
    "                #         if retry == 3:\n",
    "                #             print(\"Invalid Json:\\n\")\n",
    "                #             print(f\"{temp}\\n\")\n",
    "                #             print(f\"{err_msg}\\n\")\n",
    "                #         continue\n",
    "                #     temp = temp2\n",
    "                #     break;\n",
    "                        \n",
    "                translated.append(temp)\n",
    "                with open(target_file, 'a+') as f:\n",
    "                    f.write(temp)\n",
    "                    f.write('\\n')\n",
    "            progress_bar.update(1)\n",
    "    return errorindx,translated;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d602331-b93d-4dba-bd91-3f3022c553d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_filenames = [\"alice_in_wonderland.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e38aca25-2816-44f8-a918-a6ee713e0eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "errorbookindex=-1\n",
    "errorindx=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83a04574-4f8c-44c0-b812-73a5a30114de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice_in_wonderland.txt\n",
      "using llm: model='gemini-pro' temperature=0.5 top_p=0.85 safety_settings={<HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 10>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_HATE_SPEECH: 8>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_HARASSMENT: 7>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 9>: <HarmBlockThreshold.BLOCK_NONE: 4>} client= genai.GenerativeModel(\n",
      "   model_name='models/gemini-pro',\n",
      "   generation_config={}.\n",
      "   safety_settings={}\n",
      ") convert_system_message_to_human=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee4a83c505e4fb2a0ab725917f5690a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, source_file in enumerate(source_filenames):\n",
    "    if i < errorbookindex:\n",
    "        continue\n",
    "\n",
    "    print(source_file)\n",
    "    target = source_file + \".v7.txt\"\n",
    "    path = source_file\n",
    "    paragraphs = split_paragraph(path)[1:5]\n",
    "\n",
    "    progress=0\n",
    "    while (progress < len(paragraphs)):\n",
    "        errorindx, translated_paragraphs = autoprocess_paragraph(geminipro, paragraphs, target, start=errorindx)        \n",
    "        if errorindx < 0:\n",
    "            progress=len(paragraphs)\n",
    "        else: # errorindx >= 0:# error, retry\n",
    "            _errorindx = -1\n",
    "            for _llm in [openai]: # use optional llm to retry\n",
    "                _paragraphs = paragraphs[errorindx:errorindx+1]\n",
    "                _errorindx, _translated_paragraphs = autoprocess_paragraph(_llm, _paragraphs, target, start=0)\n",
    "                if _errorindx < 0: # retry success\n",
    "                    break\n",
    "            if _errorindx < 0: # any retry success\n",
    "                errorindx=errorindx+1 # continue next\n",
    "                progress = errorindx\n",
    "                continue\n",
    "\n",
    "    if errorindx >= 0:\n",
    "        errorbookindex=i\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb9397e-1eca-4a5c-a7c5-6dabf0a8df0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
