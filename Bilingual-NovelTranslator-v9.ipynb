{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97a66734-48c6-44f3-bd18-b3370f924820",
   "metadata": {},
   "source": [
    "# V9\n",
    "\n",
    "Well, Some novels, even with Chinese text, can still be difficult for me to read.\n",
    "As a result, I think I have to ask LLM to rewrite it first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b222aec-6c75-4ba0-a691-1787effc587b",
   "metadata": {},
   "source": [
    "## Gemini Pro API and OpenAI API\n",
    "Check [Bilingual-NovelTranslator-v1.ipynb](Bilingual-NovelTranslator-v1.ipynb) for more information.\n",
    "\n",
    "**Note** : Remember to fill you api key in `.env` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c52cbbd-3d5f-4869-bd14-5a8f1c6d0219",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import utils\n",
    "\n",
    "geminipro, openai = utils.init_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cc5aaf9-05bc-4e3f-a88d-0e07fe571fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import utils\n",
    "# refer to V6 for more info\n",
    "utils.monkeypatch_split_text_with_regex()\n",
    "\n",
    "# refer to V5 for more info\n",
    "split_paragraph = utils.split_paragraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ffab33b-25ce-4126-9f49-526130149e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_version_paragraph(llm, paragraphs, target_file, start=0):\n",
    "    from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "    from langchain_core.output_parsers.string import StrOutputParser\n",
    "    prompt = PromptTemplate.from_template(\n",
    "\"\"\"You are a professional novel writer. Your task is to rewrite certain passages of a novel into a much easier version for non-English adult readers.\n",
    "\n",
    "Do not skip the chapter title if you found one\n",
    "\n",
    "The passages came from ORC with a lots or type.\n",
    "You should fix the typos and other mistakes, but you can just skip a sentence full of nonsense garbled characters.\n",
    "\n",
    "In your output, every sentence or dialog should be separated and distinct.\n",
    "Please make sure there is a line break after every complete sentence.\n",
    "\n",
    "Just output the rewritten content, do not output any thing else.\n",
    "\n",
    "----\n",
    "The original passages is as following:\n",
    "\n",
    "{input}\n",
    "\n",
    "\"\"\")\n",
    "    print(f\"using llm: {llm}\")\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    revision=[]\n",
    "    from tqdm.notebook import tqdm, trange\n",
    "    errorindx = -1\n",
    "    with tqdm(total=len(paragraphs)) as progress_bar:\n",
    "        for i, paragraph in enumerate(paragraphs):\n",
    "            if i < start:\n",
    "                progress_bar.update(1)\n",
    "                continue\n",
    "            if len(paragraph.strip()) > 0:\n",
    "                try:\n",
    "                    # temp = \"\"\n",
    "                    # for chunk in chain.stream({\"input\": paragraph}):\n",
    "                    #     print(chunk, end=\"\", flush=True)\n",
    "                    #     temp += chunk\n",
    "                    # print(\"\\n------\\n\")    \n",
    "                    temp = chain.invoke({\"input\": paragraph})\n",
    "                except Exception as e:\n",
    "                    print(f\"Error occurs at {i}:\")\n",
    "                    print(paragraph)\n",
    "                    print(e)\n",
    "                    errorindx = i\n",
    "                    return errorindx,revision;\n",
    " \n",
    "                revision.append(temp)\n",
    "                with open(target_file, 'a+') as f:\n",
    "                    f.write(temp)\n",
    "                    # f.write('\\n')\n",
    "            progress_bar.update(1)\n",
    "    return errorindx,revision;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09d2c4c0-5a41-4c8f-bc91-bcaad59ab66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_filenames = [\"alice_in_wonderland.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9693b135-5ae6-48fd-86f6-6e50b877f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "errorbookindex=-1\n",
    "errorindx=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e56c0c0e-b826-410e-95c7-c3e74bd055d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice_in_wonderland.txt\n",
      "using llm: model='gemini-pro' temperature=0.5 top_p=0.85 safety_settings={<HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 10>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_HATE_SPEECH: 8>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_HARASSMENT: 7>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 9>: <HarmBlockThreshold.BLOCK_NONE: 4>} client= genai.GenerativeModel(\n",
      "   model_name='models/gemini-pro',\n",
      "   generation_config={}.\n",
      "   safety_settings={}\n",
      ") convert_system_message_to_human=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef817490b993456683793fce938b7cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, source_file in enumerate(source_filenames):\n",
    "    if i < errorbookindex:\n",
    "        continue\n",
    "\n",
    "    print(source_file)\n",
    "    target = source_file + \".v9.txt\"\n",
    "    path = source_file\n",
    "    paragraphs = split_paragraph(path)[1:5]\n",
    "\n",
    "    progress=0\n",
    "    while (progress < len(paragraphs)):\n",
    "        errorindx, translated_paragraphs = easy_version_paragraph(geminipro, paragraphs, target, start=errorindx)        \n",
    "        if errorindx < 0:\n",
    "            progress=len(paragraphs)\n",
    "        else: # errorindx >= 0:# error, retry\n",
    "            _errorindx = -1\n",
    "            for _llm in [openai]: # use optional llm to retry\n",
    "                _paragraphs = paragraphs[errorindx:errorindx+1]\n",
    "                _errorindx, _translated_paragraphs = easy_version_paragraph(_llm, _paragraphs, target, start=0)\n",
    "                if _errorindx < 0: # retry success\n",
    "                    break\n",
    "            if _errorindx < 0: # any retry success\n",
    "                errorindx=errorindx+1 # continue next\n",
    "                progress = errorindx\n",
    "                continue\n",
    "\n",
    "    if errorindx >= 0:\n",
    "        errorbookindex=i\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7707da7-308f-4041-8e52-f76eae761548",
   "metadata": {},
   "source": [
    "### Now we can make another bilangual audio book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb9397e-1eca-4a5c-a7c5-6dabf0a8df0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refer to V7 for more info\n",
    "autoprocess_paragraph = utils.autoprocess_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61e615ea-bd39-4904-9fac-b8e2b536cc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_filenames = [\"alice_in_wonderland.txt.v9.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "494bfba3-7d26-41cf-81d4-208eeb550f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "errorbookindex=-1\n",
    "errorindx=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6df70890-fa05-4158-bece-ab6fe0df3ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice_in_wonderland.txt.v9.txt\n",
      "using llm: model='gemini-pro' temperature=0.5 top_p=0.85 safety_settings={<HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 10>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_HATE_SPEECH: 8>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_HARASSMENT: 7>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 9>: <HarmBlockThreshold.BLOCK_NONE: 4>} client= genai.GenerativeModel(\n",
      "   model_name='models/gemini-pro',\n",
      "   generation_config={}.\n",
      "   safety_settings={}\n",
      ") convert_system_message_to_human=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f671ea87e90e46dcb941d85e52771820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, source_file in enumerate(source_filenames):\n",
    "    if i < errorbookindex:\n",
    "        continue\n",
    "\n",
    "    print(source_file)\n",
    "    target = source_file + \".json.txt\"\n",
    "    path = source_file\n",
    "    paragraphs = split_paragraph(path)\n",
    "\n",
    "    progress=0\n",
    "    while (progress < len(paragraphs)):\n",
    "        errorindx, translated_paragraphs = autoprocess_paragraph(geminipro, paragraphs, target, start=errorindx)        \n",
    "        if errorindx < 0:\n",
    "            progress=len(paragraphs)\n",
    "        else: # errorindx >= 0:# error, retry\n",
    "            _errorindx = -1\n",
    "            for _llm in [openai]: # use optional llm to retry\n",
    "                _paragraphs = paragraphs[errorindx:errorindx+1]\n",
    "                _errorindx, _translated_paragraphs = autoprocess_paragraph(_llm, _paragraphs, target, start=0)\n",
    "                if _errorindx < 0: # retry success\n",
    "                    break\n",
    "            if _errorindx < 0: # any retry success\n",
    "                errorindx=errorindx+1 # continue next\n",
    "                progress = errorindx\n",
    "                continue\n",
    "\n",
    "    if errorindx >= 0:\n",
    "        errorbookindex=i\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b032aaf-4e26-425c-958b-3a0dabe4b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "\n",
    "with open(\"alice_in_wonderland.txt.v9.txt.json.txt\", \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "pattern = re.compile(r\"```json(.*?)```\", re.DOTALL)\n",
    "matches = pattern.findall(content)\n",
    "\n",
    "merged_list = []\n",
    "\n",
    "# 解析每個區塊並將其加入到合併後的list中\n",
    "for match in matches:\n",
    "    try:\n",
    "        from json_repair import repair_json\n",
    "        json_data = repair_json(match.strip(), return_objects=True)\n",
    "        merged_list.extend(json_data)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(e)\n",
    "        print(f\"Error decoding JSON in block: {match}\")\n",
    "\n",
    "with open(\"alice_in_wonderland.txt.v9.zhtw.txt\", \"w+\") as f:\n",
    "    for ele in merged_list:\n",
    "        f.write(\"\" + ele[\"zh-tw\"] + \"\\n\")\n",
    "        f.write(\"\" + ele[\"correction\"] + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf980ed-5a73-47ea-b544-21846a999525",
   "metadata": {},
   "source": [
    "Enjoy your new novel in `alice_in_wonderland.txt.v9.zhtw.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04361e8-c05d-4dff-8bb9-8a2e45925ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
